require "params.jinc"
require "poly.jinc"

inline
fn __polyvec_add2(stack u16[MLKEM_VECN] r, stack u16[MLKEM_VECN] b) -> stack u16[MLKEM_VECN]
{
  r[0:MLKEM_N] = _poly_add2(r[0:MLKEM_N], b[0:MLKEM_N]);
  r[MLKEM_N:MLKEM_N] = _poly_add2(r[MLKEM_N:MLKEM_N], b[MLKEM_N:MLKEM_N]);
  r[2*MLKEM_N:MLKEM_N] = _poly_add2(r[2*MLKEM_N:MLKEM_N], b[2*MLKEM_N:MLKEM_N]);

  return r;
}

inline
fn __polyvec_csubq(stack u16[MLKEM_VECN] r) -> stack u16[MLKEM_VECN]
{
  r[0:MLKEM_N] = _poly_csubq(r[0:MLKEM_N]);
  r[MLKEM_N:MLKEM_N] = _poly_csubq(r[MLKEM_N:MLKEM_N]);
  r[2*MLKEM_N:MLKEM_N] = _poly_csubq(r[2*MLKEM_N:MLKEM_N]);

  return r;
}

inline
fn __polyvec_compress(reg u32 rp, stack u16[MLKEM_VECN] a)
{
  reg ptr u16[MLKEM_VECN] aa;
  reg u32 c, b, limit;
  reg u32[4] t;
  reg u32 i j;
  inline int k;

  i = 0;
  j = 0;
  
  aa = __polyvec_csubq(a);

  limit = MLKEM_VECN - 3;
  while (i < limit)
  {
    for k = 0 to 4
    {
      // was stack in x86, but for ARM this causes the compiler to say address computation is too complex
      t[k] = (32u)aa[(int)i];
      i += 1;
      t[k] <<= 10;
      t[k] += 1665;
      c = 1290167;
      // We need to multiply t[k] with 1290167 as a 64 bit number to avoid overflow
      // Therefore, we split the result into 32 high order and 32 low order bits, using UMULL
      // t[k] is the 32 high order bits, which we use and discard c as the 32 low order bits.
      // This is equivalent to shifting a 64 bit t[k] 32 bits to the right.
      c,t[k] = #UMULL(c,t[k]);
      c = 0x3ff; // 0x3ff is too large to be used as an immediate in an AND operation in ARM
      t[k] &= c; // Since we do an AND between t[k] and 0x3ff, only the last two bytes actually matter from now on
    }

    c = t[0];
    c &= 0xff;
    (u8)[rp + j] = (8u)c;
    j += 1;

    b = t[0];
    b >>= 8;
    c = t[1];
    c <<= 2;
    c |= b;
    (u8)[rp + j] = (8u)c;
    j += 1;

    b = t[1];
    b >>= 6;
    c = t[2];
    c <<= 4;
    c |= b;
    (u8)[rp + j] = (8u)c;
    j += 1;
    
    b = t[2];
    b >>= 4;
    c = t[3];
    c <<= 6;
    c |= b;
    (u8)[rp + j] = (8u)c;
    j += 1;

    
    t[3] >>= 2;
    (u8)[rp + j] = (8u)t[3];
    j += 1;
  }
}

inline
fn __i_polyvec_compress(reg ptr u8[MLKEM_POLYVECCOMPRESSEDBYTES] rp, stack u16[MLKEM_VECN] a) -> reg ptr u8[MLKEM_POLYVECCOMPRESSEDBYTES]
{
  reg ptr u16[MLKEM_VECN] aa;
  reg u32 c, b, limit;
  reg u32[4] t;
  reg u32 i j;
  inline int k;

  i = 0;
  j = 0;
  
  aa = __polyvec_csubq(a);

  limit = MLKEM_VECN - 3;
  while (i < limit)
  {
    for k = 0 to 4
    {
      t[k] = (32u)aa[(int) i];
      i += 1;
      t[k] <<= 10;
      t[k] += 1665;
      c = 1290167;
      c,t[k] = #UMULL(c,t[k]);
      c = 0x3ff;
      t[k] &= c;
    }

    c = t[0];
    c &= 0xff;
    rp[(int) j] = (8u)c;
    j += 1;

    b = t[0];
    b >>= 8;
    c = t[1];
    c <<= 2;
    c |= b;
    rp[(int) j] = (8u)c;
    j += 1;

    b = t[1];
    b >>= 6;
    c = t[2];
    c <<= 4;
    c |= b;
    rp[(int) j] = (8u)c;
    j += 1;
    
    b = t[2];
    b >>= 4;
    c = t[3];
    c <<= 6;
    c |= b;
    rp[(int) j] = (8u)c;
    j += 1;

    t[3] >>= 2;
    rp[(int) j] = (8u)t[3];
    j += 1;
  }

  return rp;
}

inline
fn __polyvec_decompress(reg u32 ap) -> stack u16[MLKEM_VECN]
{
  stack u16[MLKEM_VECN] r;
  reg ptr u16[MLKEM_VECN] r_ptr;
  reg u32[5] t;
  reg u32 d, mlkem_q, limit;
  reg u32 i j;
  inline int k;

  i = 0;
  j = 0;

  r_ptr = r;
  
  limit = MLKEM_VECN - 3;
  while (i < limit)
  {
    for k = 0 to 5
    {
      t[k] = (32u)(u8)[ap + j];
      j += 1;
    }

    d = t[1];
    t[1] >>= 2;
    d &= 0x3;
    d <<= 8;
    t[0] |= d;

    d = t[2];
    t[2] >>= 4;
    d &= 0xf;
    d <<= 6;
    t[1] |= d;

    d = t[3];
    t[3] >>= 6;
    d &= 0x3f;
    d <<= 4;
    t[2] |= d;

    d = t[4];
    d <<= 2;
    t[3] |= d;
    
    mlkem_q = MLKEM_Q;
    for k = 0 to 4
    {
      t[k] *= mlkem_q;
      t[k] += 512;
      t[k] >>= 10;
      r_ptr[(int) i] = t[k];
      i += 1;
    }
  }

  r = r_ptr;

  return r;
}

inline
fn __polyvec_frombytes(reg u32 ap) -> stack u16[MLKEM_VECN]
{
  stack u16[MLKEM_VECN] r;
  reg u32 pp;

  pp = ap;
  r[0:MLKEM_N] = _poly_frombytes(r[0:MLKEM_N], pp);
  pp += MLKEM_POLYBYTES;
  r[MLKEM_N:MLKEM_N] = _poly_frombytes(r[MLKEM_N:MLKEM_N], pp);
  pp += MLKEM_POLYBYTES;
  r[2*MLKEM_N:MLKEM_N] = _poly_frombytes(r[2*MLKEM_N:MLKEM_N], pp);

  return r;
}

inline
fn __polyvec_invntt(stack u16[MLKEM_VECN] r) -> stack u16[MLKEM_VECN]
{
  r[0:MLKEM_N] = _poly_invntt(r[0:MLKEM_N]);
  r[MLKEM_N:MLKEM_N] = _poly_invntt(r[MLKEM_N:MLKEM_N]);
  r[2*MLKEM_N:MLKEM_N] = _poly_invntt(r[2*MLKEM_N:MLKEM_N]);

  return r;
}

inline
fn __polyvec_ntt(stack u16[MLKEM_VECN] r) -> stack u16[MLKEM_VECN]
{
  r[0:MLKEM_N] = _poly_ntt(r[0:MLKEM_N]);
  r[MLKEM_N:MLKEM_N] = _poly_ntt(r[MLKEM_N:MLKEM_N]);
  r[2*MLKEM_N:MLKEM_N] = _poly_ntt(r[2*MLKEM_N:MLKEM_N]);

  return r;
}

inline
fn __polyvec_pointwise_acc(stack u16[MLKEM_VECN] a, stack u16[MLKEM_VECN] b) -> stack u16[MLKEM_N]
{
  stack u16[MLKEM_N] t;
  stack u16[MLKEM_N] r;

  r = _poly_basemul(r, a[0:MLKEM_N], b[0:MLKEM_N]);
  t = _poly_basemul(t, a[MLKEM_N:MLKEM_N], b[MLKEM_N:MLKEM_N]);
  r = _poly_add2(r, t);
  t = _poly_basemul(t, a[2*MLKEM_N:MLKEM_N], b[2*MLKEM_N:MLKEM_N]);
  r = _poly_add2(r, t);

  r = __poly_reduce(r);

  return r;
}

inline
fn __polyvec_reduce(stack u16[MLKEM_VECN] r) -> stack u16[MLKEM_VECN]
{
  r[0:MLKEM_N] = __poly_reduce(r[0:MLKEM_N]);
  r[MLKEM_N:MLKEM_N] = __poly_reduce(r[MLKEM_N:MLKEM_N]);
  r[2*MLKEM_N:MLKEM_N] = __poly_reduce(r[2*MLKEM_N:MLKEM_N]);

  return r;
}

inline
fn __polyvec_tobytes(reg u32 rp, stack u16[MLKEM_VECN] a)
{
  reg u32 pp;

  pp = rp;
  a[0:MLKEM_N] = _poly_tobytes(pp, a[0:MLKEM_N]);
  pp += MLKEM_POLYBYTES;
  a[MLKEM_N:MLKEM_N] = _poly_tobytes(pp, a[MLKEM_N:MLKEM_N]);
  pp += MLKEM_POLYBYTES;
  a[2*MLKEM_N:MLKEM_N] = _poly_tobytes(pp, a[2*MLKEM_N:MLKEM_N]);
}