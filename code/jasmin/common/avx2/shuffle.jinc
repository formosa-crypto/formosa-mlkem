/* __shuffle8: permute 32 subwords of (a,b) in sets of 8

  [0; 1; 2; 3; 4; 5; 6; 7; 16; 17; 18; 19; 20; 21; 22; 23;
   8; 9; 10; 11; 12; 13; 14; 15; 24; 25; 26; 27; 28; 29; 30; 31].
*/

inline 
fn __shuffle8(reg u256 a b) -> reg u256, reg u256
{
  reg u256 r0 r1; 
  r0 = #VPERM2I128(a,b,0x20);
  r1 = #VPERM2I128(a,b,0x31);
  return r0, r1;
}

/*  __shuffle4: permute 32 subwords of (a,b) in sets of 4

  [0; 1; 2; 3; 16; 17; 18; 19; 8; 9; 10; 11; 24; 25; 26; 27;
   4; 5; 6; 7; 20; 21; 22; 23; 12; 13; 14; 15; 28; 29; 30; 31].
*/

inline 
fn __shuffle4(reg u256 a b) -> reg u256, reg u256
{
  reg u256 r0 r1; 
  r0 = #VPUNPCKL_4u64(a,b);
  r1 = #VPUNPCKH_4u64(a,b);
  return r0, r1;
}

/*  __shuffle2: permute 32 subwords of (a,b) in sets of 2

  [0; 1; 16; 17; 4; 5; 20; 21; 8; 9; 24; 25; 12; 13; 28; 29;
   2; 3; 18; 19; 6; 7; 22; 23; 10; 11; 26; 27; 14; 15; 30; 31].
*/

inline 
fn __shuffle2(reg u256 a b) -> reg u256, reg u256
{
  reg u256 t0 t1;
  t0 = #VMOVSLDUP_256(b);
  t0 = #VPBLEND_8u32(a, t0, 0xAA);
  a = #VPSRL_4u64(a,32);
  t1 = #VPBLEND_8u32(a, b, 0xAA);
  return t0, t1;
}


/*  __shuffle1: permute 32 subwords of (a,b) in sets of 1

  [0; 16; 2; 18; 4; 20; 6; 22; 8; 24; 10; 26; 12; 28; 14; 30;
   1; 17; 3; 19; 5; 21; 7; 23; 9; 25; 11; 27; 13; 29; 15; 31].
*/

inline 
fn __shuffle1(reg u256 a b) -> reg u256, reg u256
{
  reg u256 r0 r1 t0 t1; 
  t0 = #VPSLL_8u32(b,16);
  r0 = #VPBLEND_16u16(a,t0,0xAA);
  t1 = #VPSRL_8u32(a,16);
  r1 = #VPBLEND_16u16(t1,b,0xAA);
  return r0, r1;
}

/* __nttunpack128: Aux function to convert half of a polynomial
   from AVX order to logical order of coefficients.
   Output registers contain the following permutation of
   subwords of input registers

  [0;8;16;24;32;40;48;56;64;72;80;88;96;104;112;120;
  1;9;17;25;33;41;49;57;65;73;81;89;97;105;113;121;
  2;10;18;26;34;42;50;58;66;74;82;90;98;106;114;122;
  3;11;19;27;35;43;51;59;67;75;83;91;99;107;115;123;
  4;12;20;28;36;44;52;60;68;76;84;92;100;108;116;124;
  5;13;21;29;37;45;53;61;69;77;85;93;101;109;117;125;
  6;14;22;30;38;46;54;62;70;78;86;94;102;110;118;126;
  7;15;23;31;39;47;55;63;71;79;87;95;103;111;119;127]
*/

inline
fn __nttunpack128(reg u256 r0 r1 r2 r3 r4 r5 r6 r7)
    -> reg u256, reg u256, reg u256, reg u256, reg u256, reg u256, reg u256, reg u256
{
  r0, r4 = __shuffle8(r0, r4);
  r1, r5 = __shuffle8(r1, r5);
  r2, r6 = __shuffle8(r2, r6);
  r3, r7 = __shuffle8(r3, r7);

  r0, r2 = __shuffle4(r0, r2);
  r4, r6 = __shuffle4(r4, r6);
  r1, r3 = __shuffle4(r1, r3);
  r5, r7 = __shuffle4(r5, r7);

  r0, r1 = __shuffle2(r0, r1);
  r2, r3 = __shuffle2(r2, r3);
  r4, r5 = __shuffle2(r4, r5);
  r6, r7 = __shuffle2(r6, r7);

  r0, r4 = __shuffle1(r0, r4);
  r1, r5 = __shuffle1(r1, r5);
  r2, r6 = __shuffle1(r2, r6);
  r3, r7 = __shuffle1(r3, r7);

  return r0, r4, r1, r5, r2, r6, r3, r7;
}

/* _nttunpack: Conversion from logical ordering of coefficients to avx2 order.
   Output array contains the following permutation of
   input array 

  [0; 8; 16; 24; 32; 40; 48; 56; 64; 72; 80; 88; 96; 104; 112; 120;
   1; 9; 17; 25; 33; 41; 49; 57; 65; 73; 81; 89; 97; 105; 113; 121;
   2; 10; 18; 26; 34; 42; 50; 58; 66; 74; 82; 90; 98; 106; 114; 122;
   3; 11; 19; 27; 35; 43; 51; 59; 67; 75; 83; 91; 99; 107; 115; 123;
   4; 12; 20; 28; 36; 44; 52; 60; 68; 76; 84; 92; 100; 108; 116; 124;
   5; 13; 21; 29; 37; 45; 53; 61; 69; 77; 85; 93; 101; 109; 117; 125;
   6; 14; 22; 30; 38; 46; 54; 62; 70; 78; 86; 94; 102; 110; 118; 126;
   7; 15; 23; 31; 39; 47; 55; 63; 71; 79; 87; 95; 103; 111; 119; 127;
   128; 136; 144; 152; 160; 168; 176; 184; 192; 200; 208; 216; 224; 232; 240; 248;
   129; 137; 145; 153; 161; 169; 177; 185; 193; 201; 209; 217; 225; 233; 241; 249;
   130; 138; 146; 154; 162; 170; 178; 186; 194; 202; 210; 218; 226; 234; 242; 250;
   131; 139; 147; 155; 163; 171; 179; 187; 195; 203; 211; 219; 227; 235; 243; 251;
   132; 140; 148; 156; 164; 172; 180; 188; 196; 204; 212; 220; 228; 236; 244; 252;
   133; 141; 149; 157; 165; 173; 181; 189; 197; 205; 213; 221; 229; 237; 245; 253;
   134; 142; 150; 158; 166; 174; 182; 190; 198; 206; 214; 222; 230; 238; 246; 254;
   135; 143; 151; 159; 167; 175; 183; 191; 199; 207; 215; 223; 231; 239; 247; 255].
 */

fn _nttunpack(reg ptr u16[MLKEM_N] rp) -> reg ptr u16[MLKEM_N]
{
  reg u256 r0 r1 r2 r3 r4 r5 r6 r7;

  r0 = rp.[u256 32*0];
  r1 = rp.[u256 32*1];
  r2 = rp.[u256 32*2];
  r3 = rp.[u256 32*3];
  r4 = rp.[u256 32*4];
  r5 = rp.[u256 32*5];
  r6 = rp.[u256 32*6];
  r7 = rp.[u256 32*7];

  r0, r1, r2, r3, r4, r5, r6, r7 = __nttunpack128(r0, r1, r2, r3, r4, r5, r6, r7);

  rp.[u256 32*0] = r0;
  rp.[u256 32*1] = r1;
  rp.[u256 32*2] = r2;
  rp.[u256 32*3] = r3;
  rp.[u256 32*4] = r4;
  rp.[u256 32*5] = r5;
  rp.[u256 32*6] = r6;
  rp.[u256 32*7] = r7;

  r0 = rp.[u256 32*8];
  r1 = rp.[u256 32*9];
  r2 = rp.[u256 32*10];
  r3 = rp.[u256 32*11];
  r4 = rp.[u256 32*12];
  r5 = rp.[u256 32*13];
  r6 = rp.[u256 32*14];
  r7 = rp.[u256 32*15];

  r0, r1, r2, r3, r4, r5, r6, r7 = __nttunpack128(r0, r1, r2, r3, r4, r5, r6, r7);

  rp.[u256 32*8] = r0;
  rp.[u256 32*9] = r1;
  rp.[u256 32*10] = r2;
  rp.[u256 32*11] = r3;
  rp.[u256 32*12] = r4;
  rp.[u256 32*13] = r5;
  rp.[u256 32*14] = r6;
  rp.[u256 32*15] = r7;

  return rp;
}
